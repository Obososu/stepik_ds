{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth = 5, min_samples_split = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5, min_samples_split=5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\fores\\\\Downloads\\\\train_data_tree.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>exang</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sex  exang  num\n",
       "0      1      1    1\n",
       "1      1      1    1\n",
       "2      1      0    1\n",
       "3      1      0    0\n",
       "4      1      0    1\n",
       "..   ...    ...  ...\n",
       "233    1      0    0\n",
       "234    1      1    0\n",
       "235    1      0    1\n",
       "236    1      1    1\n",
       "237    1      0    0\n",
       "\n",
       "[238 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('num', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion = 'entropy', max_depth = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7016806722689075"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(167.4, 163.07999999999998, 'X[1] <= 0.5\\nentropy = 0.996\\nsamples = 238\\nvalue = [128, 110]'),\n",
       " Text(83.7, 54.360000000000014, 'entropy = 0.903\\nsamples = 157\\nvalue = [107, 50]'),\n",
       " Text(251.10000000000002, 54.360000000000014, 'entropy = 0.826\\nsamples = 81\\nvalue = [21, 60]')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tree.plot_tree(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\iris.csv'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-0a8a93fae94a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0miris\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miris\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    433\u001b[0m             )\n\u001b[0;32m    434\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[1;34m(data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    252\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m         ]\n\u001b[1;32m--> 254\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    363\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 365\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"arrays must all be same length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 1, 1, 0, 1, 1, 2, 0, 0, 0, 0, 2, 1, 0, 1, 1, 1, 0, 0, 2,\n",
       "       0, 1, 2, 1, 1, 0, 0, 2, 0, 2, 2, 0, 2, 2, 0, 0])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametrs = {'max_depth' : range(1,11), 'min_samples_split' : range(2,11), 'min_samples_leaf' : range(1,11)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(iris, parametrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "estimator should be an estimator implementing 'fit' method, {'data': array([[5.1, 3.5, 1.4, 0.2],\n       [4.9, 3. , 1.4, 0.2],\n       [4.7, 3.2, 1.3, 0.2],\n       [4.6, 3.1, 1.5, 0.2],\n       [5. , 3.6, 1.4, 0.2],\n       [5.4, 3.9, 1.7, 0.4],\n       [4.6, 3.4, 1.4, 0.3],\n       [5. , 3.4, 1.5, 0.2],\n       [4.4, 2.9, 1.4, 0.2],\n       [4.9, 3.1, 1.5, 0.1],\n       [5.4, 3.7, 1.5, 0.2],\n       [4.8, 3.4, 1.6, 0.2],\n       [4.8, 3. , 1.4, 0.1],\n       [4.3, 3. , 1.1, 0.1],\n       [5.8, 4. , 1.2, 0.2],\n       [5.7, 4.4, 1.5, 0.4],\n       [5.4, 3.9, 1.3, 0.4],\n       [5.1, 3.5, 1.4, 0.3],\n       [5.7, 3.8, 1.7, 0.3],\n       [5.1, 3.8, 1.5, 0.3],\n       [5.4, 3.4, 1.7, 0.2],\n       [5.1, 3.7, 1.5, 0.4],\n       [4.6, 3.6, 1. , 0.2],\n       [5.1, 3.3, 1.7, 0.5],\n       [4.8, 3.4, 1.9, 0.2],\n       [5. , 3. , 1.6, 0.2],\n       [5. , 3.4, 1.6, 0.4],\n       [5.2, 3.5, 1.5, 0.2],\n       [5.2, 3.4, 1.4, 0.2],\n       [4.7, 3.2, 1.6, 0.2],\n       [4.8, 3.1, 1.6, 0.2],\n       [5.4, 3.4, 1.5, 0.4],\n       [5.2, 4.1, 1.5, 0.1],\n       [5.5, 4.2, 1.4, 0.2],\n       [4.9, 3.1, 1.5, 0.2],\n       [5. , 3.2, 1.2, 0.2],\n       [5.5, 3.5, 1.3, 0.2],\n       [4.9, 3.6, 1.4, 0.1],\n       [4.4, 3. , 1.3, 0.2],\n       [5.1, 3.4, 1.5, 0.2],\n       [5. , 3.5, 1.3, 0.3],\n       [4.5, 2.3, 1.3, 0.3],\n       [4.4, 3.2, 1.3, 0.2],\n       [5. , 3.5, 1.6, 0.6],\n       [5.1, 3.8, 1.9, 0.4],\n       [4.8, 3. , 1.4, 0.3],\n       [5.1, 3.8, 1.6, 0.2],\n       [4.6, 3.2, 1.4, 0.2],\n       [5.3, 3.7, 1.5, 0.2],\n       [5. , 3.3, 1.4, 0.2],\n       [7. , 3.2, 4.7, 1.4],\n       [6.4, 3.2, 4.5, 1.5],\n       [6.9, 3.1, 4.9, 1.5],\n       [5.5, 2.3, 4. , 1.3],\n       [6.5, 2.8, 4.6, 1.5],\n       [5.7, 2.8, 4.5, 1.3],\n       [6.3, 3.3, 4.7, 1.6],\n       [4.9, 2.4, 3.3, 1. ],\n       [6.6, 2.9, 4.6, 1.3],\n       [5.2, 2.7, 3.9, 1.4],\n       [5. , 2. , 3.5, 1. ],\n       [5.9, 3. , 4.2, 1.5],\n       [6. , 2.2, 4. , 1. ],\n       [6.1, 2.9, 4.7, 1.4],\n       [5.6, 2.9, 3.6, 1.3],\n       [6.7, 3.1, 4.4, 1.4],\n       [5.6, 3. , 4.5, 1.5],\n       [5.8, 2.7, 4.1, 1. ],\n       [6.2, 2.2, 4.5, 1.5],\n       [5.6, 2.5, 3.9, 1.1],\n       [5.9, 3.2, 4.8, 1.8],\n       [6.1, 2.8, 4. , 1.3],\n       [6.3, 2.5, 4.9, 1.5],\n       [6.1, 2.8, 4.7, 1.2],\n       [6.4, 2.9, 4.3, 1.3],\n       [6.6, 3. , 4.4, 1.4],\n       [6.8, 2.8, 4.8, 1.4],\n       [6.7, 3. , 5. , 1.7],\n       [6. , 2.9, 4.5, 1.5],\n       [5.7, 2.6, 3.5, 1. ],\n       [5.5, 2.4, 3.8, 1.1],\n       [5.5, 2.4, 3.7, 1. ],\n       [5.8, 2.7, 3.9, 1.2],\n       [6. , 2.7, 5.1, 1.6],\n       [5.4, 3. , 4.5, 1.5],\n       [6. , 3.4, 4.5, 1.6],\n       [6.7, 3.1, 4.7, 1.5],\n       [6.3, 2.3, 4.4, 1.3],\n       [5.6, 3. , 4.1, 1.3],\n       [5.5, 2.5, 4. , 1.3],\n       [5.5, 2.6, 4.4, 1.2],\n       [6.1, 3. , 4.6, 1.4],\n       [5.8, 2.6, 4. , 1.2],\n       [5. , 2.3, 3.3, 1. ],\n       [5.6, 2.7, 4.2, 1.3],\n       [5.7, 3. , 4.2, 1.2],\n       [5.7, 2.9, 4.2, 1.3],\n       [6.2, 2.9, 4.3, 1.3],\n       [5.1, 2.5, 3. , 1.1],\n       [5.7, 2.8, 4.1, 1.3],\n       [6.3, 3.3, 6. , 2.5],\n       [5.8, 2.7, 5.1, 1.9],\n       [7.1, 3. , 5.9, 2.1],\n       [6.3, 2.9, 5.6, 1.8],\n       [6.5, 3. , 5.8, 2.2],\n       [7.6, 3. , 6.6, 2.1],\n       [4.9, 2.5, 4.5, 1.7],\n       [7.3, 2.9, 6.3, 1.8],\n       [6.7, 2.5, 5.8, 1.8],\n       [7.2, 3.6, 6.1, 2.5],\n       [6.5, 3.2, 5.1, 2. ],\n       [6.4, 2.7, 5.3, 1.9],\n       [6.8, 3. , 5.5, 2.1],\n       [5.7, 2.5, 5. , 2. ],\n       [5.8, 2.8, 5.1, 2.4],\n       [6.4, 3.2, 5.3, 2.3],\n       [6.5, 3. , 5.5, 1.8],\n       [7.7, 3.8, 6.7, 2.2],\n       [7.7, 2.6, 6.9, 2.3],\n       [6. , 2.2, 5. , 1.5],\n       [6.9, 3.2, 5.7, 2.3],\n       [5.6, 2.8, 4.9, 2. ],\n       [7.7, 2.8, 6.7, 2. ],\n       [6.3, 2.7, 4.9, 1.8],\n       [6.7, 3.3, 5.7, 2.1],\n       [7.2, 3.2, 6. , 1.8],\n       [6.2, 2.8, 4.8, 1.8],\n       [6.1, 3. , 4.9, 1.8],\n       [6.4, 2.8, 5.6, 2.1],\n       [7.2, 3. , 5.8, 1.6],\n       [7.4, 2.8, 6.1, 1.9],\n       [7.9, 3.8, 6.4, 2. ],\n       [6.4, 2.8, 5.6, 2.2],\n       [6.3, 2.8, 5.1, 1.5],\n       [6.1, 2.6, 5.6, 1.4],\n       [7.7, 3. , 6.1, 2.3],\n       [6.3, 3.4, 5.6, 2.4],\n       [6.4, 3.1, 5.5, 1.8],\n       [6. , 3. , 4.8, 1.8],\n       [6.9, 3.1, 5.4, 2.1],\n       [6.7, 3.1, 5.6, 2.4],\n       [6.9, 3.1, 5.1, 2.3],\n       [5.8, 2.7, 5.1, 1.9],\n       [6.8, 3.2, 5.9, 2.3],\n       [6.7, 3.3, 5.7, 2.5],\n       [6.7, 3. , 5.2, 2.3],\n       [6.3, 2.5, 5. , 1.9],\n       [6.5, 3. , 5.2, 2. ],\n       [6.2, 3.4, 5.4, 2.3],\n       [5.9, 3. , 5.1, 1.8]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), 'frame': None, 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'), 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...', 'feature_names': ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'], 'filename': 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\iris.csv'} was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-104-4d29271945bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    652\u001b[0m         \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 654\u001b[1;33m         scorers, self.multimetric_ = _check_multimetric_scoring(\n\u001b[0m\u001b[0;32m    655\u001b[0m             self.estimator, scoring=self.scoring)\n\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36m_check_multimetric_scoring\u001b[1;34m(estimator, scoring)\u001b[0m\n\u001b[0;32m    473\u001b[0m     if callable(scoring) or scoring is None or isinstance(scoring,\n\u001b[0;32m    474\u001b[0m                                                           str):\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mscorers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"score\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mscorers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[1;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[0;32m    400\u001b[0m     \"\"\"\n\u001b[0;32m    401\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m         raise TypeError(\"estimator should be an estimator implementing \"\n\u001b[0m\u001b[0;32m    403\u001b[0m                         \"'fit' method, %r was passed\" % estimator)\n\u001b[0;32m    404\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: estimator should be an estimator implementing 'fit' method, {'data': array([[5.1, 3.5, 1.4, 0.2],\n       [4.9, 3. , 1.4, 0.2],\n       [4.7, 3.2, 1.3, 0.2],\n       [4.6, 3.1, 1.5, 0.2],\n       [5. , 3.6, 1.4, 0.2],\n       [5.4, 3.9, 1.7, 0.4],\n       [4.6, 3.4, 1.4, 0.3],\n       [5. , 3.4, 1.5, 0.2],\n       [4.4, 2.9, 1.4, 0.2],\n       [4.9, 3.1, 1.5, 0.1],\n       [5.4, 3.7, 1.5, 0.2],\n       [4.8, 3.4, 1.6, 0.2],\n       [4.8, 3. , 1.4, 0.1],\n       [4.3, 3. , 1.1, 0.1],\n       [5.8, 4. , 1.2, 0.2],\n       [5.7, 4.4, 1.5, 0.4],\n       [5.4, 3.9, 1.3, 0.4],\n       [5.1, 3.5, 1.4, 0.3],\n       [5.7, 3.8, 1.7, 0.3],\n       [5.1, 3.8, 1.5, 0.3],\n       [5.4, 3.4, 1.7, 0.2],\n       [5.1, 3.7, 1.5, 0.4],\n       [4.6, 3.6, 1. , 0.2],\n       [5.1, 3.3, 1.7, 0.5],\n       [4.8, 3.4, 1.9, 0.2],\n       [5. , 3. , 1.6, 0.2],\n       [5. , 3.4, 1.6, 0.4],\n       [5.2, 3.5, 1.5, 0.2],\n       [5.2, 3.4, 1.4, 0.2],\n       [4.7, 3.2, 1.6, 0.2],\n       [4.8, 3.1, 1.6, 0.2],\n       [5.4, 3.4, 1.5, 0.4],\n       [5.2, 4.1, 1.5, 0.1],\n       [5.5, 4.2, 1.4, 0.2],\n       [4.9, 3.1, 1.5, 0.2],\n       [5. , 3.2, 1.2, 0.2],\n       [5.5, 3.5, 1.3, 0.2],\n       [4.9, 3.6, 1.4, 0.1],\n       [4.4, 3. , 1.3, 0.2],\n       [5.1, 3.4, 1.5, 0.2],\n       [5. , 3.5, 1.3, 0.3],\n       [4.5, 2.3, 1.3, 0.3],\n       [4.4, 3.2, 1.3, 0.2],\n       [5. , 3.5, 1.6, 0.6],\n       [5.1, 3.8, 1.9, 0.4],\n       [4.8, 3. , 1.4, 0.3],\n       [5.1, 3.8, 1.6, 0.2],\n       [4.6, 3.2, 1.4, 0.2],\n       [5.3, 3.7, 1.5, 0.2],\n       [5. , 3.3, 1.4, 0.2],\n       [7. , 3.2, 4.7, 1.4],\n       [6.4, 3.2, 4.5, 1.5],\n       [6.9, 3.1, 4.9, 1.5],\n       [5.5, 2.3, 4. , 1.3],\n       [6.5, 2.8, 4.6, 1.5],\n       [5.7, 2.8, 4.5, 1.3],\n       [6.3, 3.3, 4.7, 1.6],\n       [4.9, 2.4, 3.3, 1. ],\n       [6.6, 2.9, 4.6, 1.3],\n       [5.2, 2.7, 3.9, 1.4],\n       [5. , 2. , 3.5, 1. ],\n       [5.9, 3. , 4.2, 1.5],\n       [6. , 2.2, 4. , 1. ],\n       [6.1, 2.9, 4.7, 1.4],\n       [5.6, 2.9, 3.6, 1.3],\n       [6.7, 3.1, 4.4, 1.4],\n       [5.6, 3. , 4.5, 1.5],\n       [5.8, 2.7, 4.1, 1. ],\n       [6.2, 2.2, 4.5, 1.5],\n       [5.6, 2.5, 3.9, 1.1],\n       [5.9, 3.2, 4.8, 1.8],\n       [6.1, 2.8, 4. , 1.3],\n       [6.3, 2.5, 4.9, 1.5],\n       [6.1, 2.8, 4.7, 1.2],\n       [6.4, 2.9, 4.3, 1.3],\n       [6.6, 3. , 4.4, 1.4],\n       [6.8, 2.8, 4.8, 1.4],\n       [6.7, 3. , 5. , 1.7],\n       [6. , 2.9, 4.5, 1.5],\n       [5.7, 2.6, 3.5, 1. ],\n       [5.5, 2.4, 3.8, 1.1],\n       [5.5, 2.4, 3.7, 1. ],\n       [5.8, 2.7, 3.9, 1.2],\n       [6. , 2.7, 5.1, 1.6],\n       [5.4, 3. , 4.5, 1.5],\n       [6. , 3.4, 4.5, 1.6],\n       [6.7, 3.1, 4.7, 1.5],\n       [6.3, 2.3, 4.4, 1.3],\n       [5.6, 3. , 4.1, 1.3],\n       [5.5, 2.5, 4. , 1.3],\n       [5.5, 2.6, 4.4, 1.2],\n       [6.1, 3. , 4.6, 1.4],\n       [5.8, 2.6, 4. , 1.2],\n       [5. , 2.3, 3.3, 1. ],\n       [5.6, 2.7, 4.2, 1.3],\n       [5.7, 3. , 4.2, 1.2],\n       [5.7, 2.9, 4.2, 1.3],\n       [6.2, 2.9, 4.3, 1.3],\n       [5.1, 2.5, 3. , 1.1],\n       [5.7, 2.8, 4.1, 1.3],\n       [6.3, 3.3, 6. , 2.5],\n       [5.8, 2.7, 5.1, 1.9],\n       [7.1, 3. , 5.9, 2.1],\n       [6.3, 2.9, 5.6, 1.8],\n       [6.5, 3. , 5.8, 2.2],\n       [7.6, 3. , 6.6, 2.1],\n       [4.9, 2.5, 4.5, 1.7],\n       [7.3, 2.9, 6.3, 1.8],\n       [6.7, 2.5, 5.8, 1.8],\n       [7.2, 3.6, 6.1, 2.5],\n       [6.5, 3.2, 5.1, 2. ],\n       [6.4, 2.7, 5.3, 1.9],\n       [6.8, 3. , 5.5, 2.1],\n       [5.7, 2.5, 5. , 2. ],\n       [5.8, 2.8, 5.1, 2.4],\n       [6.4, 3.2, 5.3, 2.3],\n       [6.5, 3. , 5.5, 1.8],\n       [7.7, 3.8, 6.7, 2.2],\n       [7.7, 2.6, 6.9, 2.3],\n       [6. , 2.2, 5. , 1.5],\n       [6.9, 3.2, 5.7, 2.3],\n       [5.6, 2.8, 4.9, 2. ],\n       [7.7, 2.8, 6.7, 2. ],\n       [6.3, 2.7, 4.9, 1.8],\n       [6.7, 3.3, 5.7, 2.1],\n       [7.2, 3.2, 6. , 1.8],\n       [6.2, 2.8, 4.8, 1.8],\n       [6.1, 3. , 4.9, 1.8],\n       [6.4, 2.8, 5.6, 2.1],\n       [7.2, 3. , 5.8, 1.6],\n       [7.4, 2.8, 6.1, 1.9],\n       [7.9, 3.8, 6.4, 2. ],\n       [6.4, 2.8, 5.6, 2.2],\n       [6.3, 2.8, 5.1, 1.5],\n       [6.1, 2.6, 5.6, 1.4],\n       [7.7, 3. , 6.1, 2.3],\n       [6.3, 3.4, 5.6, 2.4],\n       [6.4, 3.1, 5.5, 1.8],\n       [6. , 3. , 4.8, 1.8],\n       [6.9, 3.1, 5.4, 2.1],\n       [6.7, 3.1, 5.6, 2.4],\n       [6.9, 3.1, 5.1, 2.3],\n       [5.8, 2.7, 5.1, 1.9],\n       [6.8, 3.2, 5.9, 2.3],\n       [6.7, 3.3, 5.7, 2.5],\n       [6.7, 3. , 5.2, 2.3],\n       [6.3, 2.5, 5. , 1.9],\n       [6.5, 3. , 5.2, 2. ],\n       [6.2, 3.4, 5.4, 2.3],\n       [5.9, 3. , 5.1, 1.8]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), 'frame': None, 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'), 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...', 'feature_names': ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'], 'filename': 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\iris.csv'} was passed"
     ]
    }
   ],
   "source": [
    "search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_impurity_split', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'presort', 'random_state', 'splitter'])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tree = search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9210526315789473"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_tree.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\iris.csv'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "estimator should be an estimator implementing 'fit' method, {'data': array([[5.1, 3.5, 1.4, 0.2],\n       [4.9, 3. , 1.4, 0.2],\n       [4.7, 3.2, 1.3, 0.2],\n       [4.6, 3.1, 1.5, 0.2],\n       [5. , 3.6, 1.4, 0.2],\n       [5.4, 3.9, 1.7, 0.4],\n       [4.6, 3.4, 1.4, 0.3],\n       [5. , 3.4, 1.5, 0.2],\n       [4.4, 2.9, 1.4, 0.2],\n       [4.9, 3.1, 1.5, 0.1],\n       [5.4, 3.7, 1.5, 0.2],\n       [4.8, 3.4, 1.6, 0.2],\n       [4.8, 3. , 1.4, 0.1],\n       [4.3, 3. , 1.1, 0.1],\n       [5.8, 4. , 1.2, 0.2],\n       [5.7, 4.4, 1.5, 0.4],\n       [5.4, 3.9, 1.3, 0.4],\n       [5.1, 3.5, 1.4, 0.3],\n       [5.7, 3.8, 1.7, 0.3],\n       [5.1, 3.8, 1.5, 0.3],\n       [5.4, 3.4, 1.7, 0.2],\n       [5.1, 3.7, 1.5, 0.4],\n       [4.6, 3.6, 1. , 0.2],\n       [5.1, 3.3, 1.7, 0.5],\n       [4.8, 3.4, 1.9, 0.2],\n       [5. , 3. , 1.6, 0.2],\n       [5. , 3.4, 1.6, 0.4],\n       [5.2, 3.5, 1.5, 0.2],\n       [5.2, 3.4, 1.4, 0.2],\n       [4.7, 3.2, 1.6, 0.2],\n       [4.8, 3.1, 1.6, 0.2],\n       [5.4, 3.4, 1.5, 0.4],\n       [5.2, 4.1, 1.5, 0.1],\n       [5.5, 4.2, 1.4, 0.2],\n       [4.9, 3.1, 1.5, 0.2],\n       [5. , 3.2, 1.2, 0.2],\n       [5.5, 3.5, 1.3, 0.2],\n       [4.9, 3.6, 1.4, 0.1],\n       [4.4, 3. , 1.3, 0.2],\n       [5.1, 3.4, 1.5, 0.2],\n       [5. , 3.5, 1.3, 0.3],\n       [4.5, 2.3, 1.3, 0.3],\n       [4.4, 3.2, 1.3, 0.2],\n       [5. , 3.5, 1.6, 0.6],\n       [5.1, 3.8, 1.9, 0.4],\n       [4.8, 3. , 1.4, 0.3],\n       [5.1, 3.8, 1.6, 0.2],\n       [4.6, 3.2, 1.4, 0.2],\n       [5.3, 3.7, 1.5, 0.2],\n       [5. , 3.3, 1.4, 0.2],\n       [7. , 3.2, 4.7, 1.4],\n       [6.4, 3.2, 4.5, 1.5],\n       [6.9, 3.1, 4.9, 1.5],\n       [5.5, 2.3, 4. , 1.3],\n       [6.5, 2.8, 4.6, 1.5],\n       [5.7, 2.8, 4.5, 1.3],\n       [6.3, 3.3, 4.7, 1.6],\n       [4.9, 2.4, 3.3, 1. ],\n       [6.6, 2.9, 4.6, 1.3],\n       [5.2, 2.7, 3.9, 1.4],\n       [5. , 2. , 3.5, 1. ],\n       [5.9, 3. , 4.2, 1.5],\n       [6. , 2.2, 4. , 1. ],\n       [6.1, 2.9, 4.7, 1.4],\n       [5.6, 2.9, 3.6, 1.3],\n       [6.7, 3.1, 4.4, 1.4],\n       [5.6, 3. , 4.5, 1.5],\n       [5.8, 2.7, 4.1, 1. ],\n       [6.2, 2.2, 4.5, 1.5],\n       [5.6, 2.5, 3.9, 1.1],\n       [5.9, 3.2, 4.8, 1.8],\n       [6.1, 2.8, 4. , 1.3],\n       [6.3, 2.5, 4.9, 1.5],\n       [6.1, 2.8, 4.7, 1.2],\n       [6.4, 2.9, 4.3, 1.3],\n       [6.6, 3. , 4.4, 1.4],\n       [6.8, 2.8, 4.8, 1.4],\n       [6.7, 3. , 5. , 1.7],\n       [6. , 2.9, 4.5, 1.5],\n       [5.7, 2.6, 3.5, 1. ],\n       [5.5, 2.4, 3.8, 1.1],\n       [5.5, 2.4, 3.7, 1. ],\n       [5.8, 2.7, 3.9, 1.2],\n       [6. , 2.7, 5.1, 1.6],\n       [5.4, 3. , 4.5, 1.5],\n       [6. , 3.4, 4.5, 1.6],\n       [6.7, 3.1, 4.7, 1.5],\n       [6.3, 2.3, 4.4, 1.3],\n       [5.6, 3. , 4.1, 1.3],\n       [5.5, 2.5, 4. , 1.3],\n       [5.5, 2.6, 4.4, 1.2],\n       [6.1, 3. , 4.6, 1.4],\n       [5.8, 2.6, 4. , 1.2],\n       [5. , 2.3, 3.3, 1. ],\n       [5.6, 2.7, 4.2, 1.3],\n       [5.7, 3. , 4.2, 1.2],\n       [5.7, 2.9, 4.2, 1.3],\n       [6.2, 2.9, 4.3, 1.3],\n       [5.1, 2.5, 3. , 1.1],\n       [5.7, 2.8, 4.1, 1.3],\n       [6.3, 3.3, 6. , 2.5],\n       [5.8, 2.7, 5.1, 1.9],\n       [7.1, 3. , 5.9, 2.1],\n       [6.3, 2.9, 5.6, 1.8],\n       [6.5, 3. , 5.8, 2.2],\n       [7.6, 3. , 6.6, 2.1],\n       [4.9, 2.5, 4.5, 1.7],\n       [7.3, 2.9, 6.3, 1.8],\n       [6.7, 2.5, 5.8, 1.8],\n       [7.2, 3.6, 6.1, 2.5],\n       [6.5, 3.2, 5.1, 2. ],\n       [6.4, 2.7, 5.3, 1.9],\n       [6.8, 3. , 5.5, 2.1],\n       [5.7, 2.5, 5. , 2. ],\n       [5.8, 2.8, 5.1, 2.4],\n       [6.4, 3.2, 5.3, 2.3],\n       [6.5, 3. , 5.5, 1.8],\n       [7.7, 3.8, 6.7, 2.2],\n       [7.7, 2.6, 6.9, 2.3],\n       [6. , 2.2, 5. , 1.5],\n       [6.9, 3.2, 5.7, 2.3],\n       [5.6, 2.8, 4.9, 2. ],\n       [7.7, 2.8, 6.7, 2. ],\n       [6.3, 2.7, 4.9, 1.8],\n       [6.7, 3.3, 5.7, 2.1],\n       [7.2, 3.2, 6. , 1.8],\n       [6.2, 2.8, 4.8, 1.8],\n       [6.1, 3. , 4.9, 1.8],\n       [6.4, 2.8, 5.6, 2.1],\n       [7.2, 3. , 5.8, 1.6],\n       [7.4, 2.8, 6.1, 1.9],\n       [7.9, 3.8, 6.4, 2. ],\n       [6.4, 2.8, 5.6, 2.2],\n       [6.3, 2.8, 5.1, 1.5],\n       [6.1, 2.6, 5.6, 1.4],\n       [7.7, 3. , 6.1, 2.3],\n       [6.3, 3.4, 5.6, 2.4],\n       [6.4, 3.1, 5.5, 1.8],\n       [6. , 3. , 4.8, 1.8],\n       [6.9, 3.1, 5.4, 2.1],\n       [6.7, 3.1, 5.6, 2.4],\n       [6.9, 3.1, 5.1, 2.3],\n       [5.8, 2.7, 5.1, 1.9],\n       [6.8, 3.2, 5.9, 2.3],\n       [6.7, 3.3, 5.7, 2.5],\n       [6.7, 3. , 5.2, 2.3],\n       [6.3, 2.5, 5. , 1.9],\n       [6.5, 3. , 5.2, 2. ],\n       [6.2, 3.4, 5.4, 2.3],\n       [5.9, 3. , 5.1, 1.8]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), 'frame': None, 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'), 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...', 'feature_names': ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'], 'filename': 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\iris.csv'} was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-2e1375f07d3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mparametrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'max_depth'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'min_samples_split'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'min_samples_leaf'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0msearch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miris\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparametrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0msearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mbest_tree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    652\u001b[0m         \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 654\u001b[1;33m         scorers, self.multimetric_ = _check_multimetric_scoring(\n\u001b[0m\u001b[0;32m    655\u001b[0m             self.estimator, scoring=self.scoring)\n\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36m_check_multimetric_scoring\u001b[1;34m(estimator, scoring)\u001b[0m\n\u001b[0;32m    473\u001b[0m     if callable(scoring) or scoring is None or isinstance(scoring,\n\u001b[0;32m    474\u001b[0m                                                           str):\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mscorers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"score\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mscorers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[1;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[0;32m    400\u001b[0m     \"\"\"\n\u001b[0;32m    401\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m         raise TypeError(\"estimator should be an estimator implementing \"\n\u001b[0m\u001b[0;32m    403\u001b[0m                         \"'fit' method, %r was passed\" % estimator)\n\u001b[0;32m    404\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: estimator should be an estimator implementing 'fit' method, {'data': array([[5.1, 3.5, 1.4, 0.2],\n       [4.9, 3. , 1.4, 0.2],\n       [4.7, 3.2, 1.3, 0.2],\n       [4.6, 3.1, 1.5, 0.2],\n       [5. , 3.6, 1.4, 0.2],\n       [5.4, 3.9, 1.7, 0.4],\n       [4.6, 3.4, 1.4, 0.3],\n       [5. , 3.4, 1.5, 0.2],\n       [4.4, 2.9, 1.4, 0.2],\n       [4.9, 3.1, 1.5, 0.1],\n       [5.4, 3.7, 1.5, 0.2],\n       [4.8, 3.4, 1.6, 0.2],\n       [4.8, 3. , 1.4, 0.1],\n       [4.3, 3. , 1.1, 0.1],\n       [5.8, 4. , 1.2, 0.2],\n       [5.7, 4.4, 1.5, 0.4],\n       [5.4, 3.9, 1.3, 0.4],\n       [5.1, 3.5, 1.4, 0.3],\n       [5.7, 3.8, 1.7, 0.3],\n       [5.1, 3.8, 1.5, 0.3],\n       [5.4, 3.4, 1.7, 0.2],\n       [5.1, 3.7, 1.5, 0.4],\n       [4.6, 3.6, 1. , 0.2],\n       [5.1, 3.3, 1.7, 0.5],\n       [4.8, 3.4, 1.9, 0.2],\n       [5. , 3. , 1.6, 0.2],\n       [5. , 3.4, 1.6, 0.4],\n       [5.2, 3.5, 1.5, 0.2],\n       [5.2, 3.4, 1.4, 0.2],\n       [4.7, 3.2, 1.6, 0.2],\n       [4.8, 3.1, 1.6, 0.2],\n       [5.4, 3.4, 1.5, 0.4],\n       [5.2, 4.1, 1.5, 0.1],\n       [5.5, 4.2, 1.4, 0.2],\n       [4.9, 3.1, 1.5, 0.2],\n       [5. , 3.2, 1.2, 0.2],\n       [5.5, 3.5, 1.3, 0.2],\n       [4.9, 3.6, 1.4, 0.1],\n       [4.4, 3. , 1.3, 0.2],\n       [5.1, 3.4, 1.5, 0.2],\n       [5. , 3.5, 1.3, 0.3],\n       [4.5, 2.3, 1.3, 0.3],\n       [4.4, 3.2, 1.3, 0.2],\n       [5. , 3.5, 1.6, 0.6],\n       [5.1, 3.8, 1.9, 0.4],\n       [4.8, 3. , 1.4, 0.3],\n       [5.1, 3.8, 1.6, 0.2],\n       [4.6, 3.2, 1.4, 0.2],\n       [5.3, 3.7, 1.5, 0.2],\n       [5. , 3.3, 1.4, 0.2],\n       [7. , 3.2, 4.7, 1.4],\n       [6.4, 3.2, 4.5, 1.5],\n       [6.9, 3.1, 4.9, 1.5],\n       [5.5, 2.3, 4. , 1.3],\n       [6.5, 2.8, 4.6, 1.5],\n       [5.7, 2.8, 4.5, 1.3],\n       [6.3, 3.3, 4.7, 1.6],\n       [4.9, 2.4, 3.3, 1. ],\n       [6.6, 2.9, 4.6, 1.3],\n       [5.2, 2.7, 3.9, 1.4],\n       [5. , 2. , 3.5, 1. ],\n       [5.9, 3. , 4.2, 1.5],\n       [6. , 2.2, 4. , 1. ],\n       [6.1, 2.9, 4.7, 1.4],\n       [5.6, 2.9, 3.6, 1.3],\n       [6.7, 3.1, 4.4, 1.4],\n       [5.6, 3. , 4.5, 1.5],\n       [5.8, 2.7, 4.1, 1. ],\n       [6.2, 2.2, 4.5, 1.5],\n       [5.6, 2.5, 3.9, 1.1],\n       [5.9, 3.2, 4.8, 1.8],\n       [6.1, 2.8, 4. , 1.3],\n       [6.3, 2.5, 4.9, 1.5],\n       [6.1, 2.8, 4.7, 1.2],\n       [6.4, 2.9, 4.3, 1.3],\n       [6.6, 3. , 4.4, 1.4],\n       [6.8, 2.8, 4.8, 1.4],\n       [6.7, 3. , 5. , 1.7],\n       [6. , 2.9, 4.5, 1.5],\n       [5.7, 2.6, 3.5, 1. ],\n       [5.5, 2.4, 3.8, 1.1],\n       [5.5, 2.4, 3.7, 1. ],\n       [5.8, 2.7, 3.9, 1.2],\n       [6. , 2.7, 5.1, 1.6],\n       [5.4, 3. , 4.5, 1.5],\n       [6. , 3.4, 4.5, 1.6],\n       [6.7, 3.1, 4.7, 1.5],\n       [6.3, 2.3, 4.4, 1.3],\n       [5.6, 3. , 4.1, 1.3],\n       [5.5, 2.5, 4. , 1.3],\n       [5.5, 2.6, 4.4, 1.2],\n       [6.1, 3. , 4.6, 1.4],\n       [5.8, 2.6, 4. , 1.2],\n       [5. , 2.3, 3.3, 1. ],\n       [5.6, 2.7, 4.2, 1.3],\n       [5.7, 3. , 4.2, 1.2],\n       [5.7, 2.9, 4.2, 1.3],\n       [6.2, 2.9, 4.3, 1.3],\n       [5.1, 2.5, 3. , 1.1],\n       [5.7, 2.8, 4.1, 1.3],\n       [6.3, 3.3, 6. , 2.5],\n       [5.8, 2.7, 5.1, 1.9],\n       [7.1, 3. , 5.9, 2.1],\n       [6.3, 2.9, 5.6, 1.8],\n       [6.5, 3. , 5.8, 2.2],\n       [7.6, 3. , 6.6, 2.1],\n       [4.9, 2.5, 4.5, 1.7],\n       [7.3, 2.9, 6.3, 1.8],\n       [6.7, 2.5, 5.8, 1.8],\n       [7.2, 3.6, 6.1, 2.5],\n       [6.5, 3.2, 5.1, 2. ],\n       [6.4, 2.7, 5.3, 1.9],\n       [6.8, 3. , 5.5, 2.1],\n       [5.7, 2.5, 5. , 2. ],\n       [5.8, 2.8, 5.1, 2.4],\n       [6.4, 3.2, 5.3, 2.3],\n       [6.5, 3. , 5.5, 1.8],\n       [7.7, 3.8, 6.7, 2.2],\n       [7.7, 2.6, 6.9, 2.3],\n       [6. , 2.2, 5. , 1.5],\n       [6.9, 3.2, 5.7, 2.3],\n       [5.6, 2.8, 4.9, 2. ],\n       [7.7, 2.8, 6.7, 2. ],\n       [6.3, 2.7, 4.9, 1.8],\n       [6.7, 3.3, 5.7, 2.1],\n       [7.2, 3.2, 6. , 1.8],\n       [6.2, 2.8, 4.8, 1.8],\n       [6.1, 3. , 4.9, 1.8],\n       [6.4, 2.8, 5.6, 2.1],\n       [7.2, 3. , 5.8, 1.6],\n       [7.4, 2.8, 6.1, 1.9],\n       [7.9, 3.8, 6.4, 2. ],\n       [6.4, 2.8, 5.6, 2.2],\n       [6.3, 2.8, 5.1, 1.5],\n       [6.1, 2.6, 5.6, 1.4],\n       [7.7, 3. , 6.1, 2.3],\n       [6.3, 3.4, 5.6, 2.4],\n       [6.4, 3.1, 5.5, 1.8],\n       [6. , 3. , 4.8, 1.8],\n       [6.9, 3.1, 5.4, 2.1],\n       [6.7, 3.1, 5.6, 2.4],\n       [6.9, 3.1, 5.1, 2.3],\n       [5.8, 2.7, 5.1, 1.9],\n       [6.8, 3.2, 5.9, 2.3],\n       [6.7, 3.3, 5.7, 2.5],\n       [6.7, 3. , 5.2, 2.3],\n       [6.3, 2.5, 5. , 1.9],\n       [6.5, 3. , 5.2, 2. ],\n       [6.2, 3.4, 5.4, 2.3],\n       [5.9, 3. , 5.1, 1.8]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), 'frame': None, 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'), 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...', 'feature_names': ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'], 'filename': 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\iris.csv'} was passed"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "parametrs = {'max_depth' : range(1,11), 'min_samples_split' : range(2,11), 'min_samples_leaf' : range(1,11)}\n",
    "search = GridSearchCV(iris, parametrs, cv = 5)\n",
    "search.fit(X, y)\n",
    "best_tree = search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "parametrs = {'criterion': ['gini', 'entropy'], 'max_depth': range(1, 10), 'min_samples_split': range(2, 10), 'min_samples_leaf': range(1, 10)}\n",
    "\n",
    "search = GridSearchCV(dt, parametrs, cv=5)\n",
    "search.fit(X, y)\n",
    "\n",
    "best_tree = search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
